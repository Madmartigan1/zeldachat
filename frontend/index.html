<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="icon" type="image/png" href="zelda.PNG" />
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Zelda Chat</title>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      margin: 0;
      padding: 0;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: flex-start;
	  /* soft ocean color */
      background: radial-gradient(circle at top,
		#e3f6ff 0,
		#c4e8ff 35%,
		#94d2ff 70%,
		#4a90e2 100%);
	  color: #222;
    }

    /* Main page wrapper */
    #page {
      width: 100%;
      max-width: 960px;
      margin: 16px;
      padding: 16px 16px 20px;
      border-radius: 16px;
      background: rgba(255, 255, 255, 0.96);
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.12);
      box-sizing: border-box;
    }
    h1 {
      text-align: center;
	  margin-top: 0;
      margin-bottom: 16px;
      font-weight: 600;
      letter-spacing: 0.03em;
      color: #4a2f24;
    }
    #layout {
      display: flex;
      gap: 16px;
      align-items: stretch;
    }
    #avatarPanel {
      width: 260px;
      text-align: center;
    }

    /* Keep a fixed portrait box so PNG and video match perfectly */
    #avatarWrapper {
      position: relative;
      display: inline-block;
      width: 100%;
      aspect-ratio: 2 / 3;  /* fits your 1024x1536 image nicely */
      border-radius: 16px;
      overflow: hidden;
      border: 1px solid #ccc;
      box-shadow: 0 0 8px rgba(0, 0, 0, 0.1);
      transition: box-shadow 0.3s ease;
      margin: 0 auto 8px auto;
      background: #d6c2aa;
    }

    #avatarWrapper img,
    #avatarWrapper video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    /* PNG is the default idle view */
    #avatarImg {
      display: block;
      z-index: 1;
    }

    #avatarVideo {
      display: none;       /* only visible while speaking */
      z-index: 2;
    }

    /* When playing, swap to video */
    #avatarWrapper.playing #avatarImg {
      display: none;
    }
    #avatarWrapper.playing #avatarVideo {
      display: block;
    }

	
    /* Tone-based glow around the avatar */
    #avatarWrapper.tone-sympathetic {
      box-shadow: 0 0 18px rgba(120, 180, 255, 0.9);
    }

    #avatarWrapper.tone-encouraging {
      box-shadow: 0 0 18px rgba(120, 220, 160, 0.9);
    }

    #avatarWrapper.tone-celebratory {
      box-shadow: 0 0 18px rgba(255, 210, 120, 0.95);
    }

    #avatarWrapper.tone-caution {
      box-shadow: 0 0 18px rgba(255, 160, 80, 0.95);
    }

    #avatarWrapper.tone-warm_playful {
      box-shadow: 0 0 18px rgba(255, 150, 200, 0.9);
    }

    #avatarWrapper.tone-neutral {
      box-shadow: 0 0 8px rgba(0, 0, 0, 0.15);
    }
    #chatPanel {
      flex: 1;
      display: flex;
      flex-direction: column;
    }
    #chat {
      border: 1px solid #e2d0c5;
      border-radius: 10px;
      padding: 10px;
      height: 380px;
      max-height: 60vh;
      overflow-y: auto;
      margin-bottom: 10px;
      background: #fffaf6;
      display: flex;
      flex-direction: column;
      box-sizing: border-box;
    }
    .message {
      margin: 6px 0;
      padding: 6px 8px;
      border-radius: 6px;
      max-width: 80%;
      white-space: pre-wrap;
    }
    .user {
      background: #dbe7ff;
      align-self: flex-end;
      margin-left: auto;
    }
    .assistant {
      background: #e7ffe6;
      align-self: flex-start;
      margin-right: auto;
    }
    #inputRow {
      display: flex;
      gap: 6px;
    }
    #messageInput {
      flex: 1;
      padding: 8px;
      font-size: 14px;
	  min-height: 48px;
      /* height will be controlled via JS to auto-fit content */
      resize: none;
      box-sizing: border-box;
      overflow-y: hidden; /* until we hit the max height in JS */
    }
    #sendBtn,
    #voiceBtn,
    #micBtn {
      padding: 8px 14px;
      font-size: 14px;
      cursor: pointer;
    }
    #voiceBtn,
    #micBtn {
      min-width: 40px;
    }
    #status {
      font-size: 12px;
      color: #7a665a;
      margin-top: 4px;
      min-height: 16px;
    }
	/* Recording equalizer indicator */
    #recordingIndicator {
      display: inline-flex;
      gap: 3px;
      align-items: flex-end;
      height: 12px;
      margin-right: 6px;
    }

    .record-bar {
      width: 3px;
      border-radius: 2px;
      background: #d33;
      animation: equalize 0.6s infinite ease-in-out;
    }

    .record-bar:nth-child(2) {
      animation-delay: 0.15s;
    }

    .record-bar:nth-child(3) {
      animation-delay: 0.3s;
    }

    @keyframes equalize {
      0%   { height: 3px;  opacity: 0.4; }
      50%  { height: 12px; opacity: 1;   }
      100% { height: 3px;  opacity: 0.4; }
    }
	/* Responsive layout for smaller screens */
    @media (max-width: 800px) {
      #page {
        margin: 8px;
        padding: 12px;
      }

      #layout {
        flex-direction: column;
      }

      #avatarPanel {
        width: 100%;
        max-width: 320px;
        margin: 0 auto 12px auto;
      }

      #chat {
        height: 50vh;
        max-height: 55vh;
      }

      #inputRow {
        flex-wrap: wrap;
      }

      #messageInput {
        min-height: 40px;
      }
    }

    /* Landscape phones: give chat more vertical room */
    @media (max-width: 900px) and (orientation: landscape) {
      #chat {
        height: 60vh;
        max-height: 65vh;
      }
    }
	
  </style>
</head>
<body>
  <div id="page">
    <h1>Chat with Zelda (beta)</h1>

    <div id="layout">
    <div id="avatarPanel">
      <div id="avatarWrapper">
        <!-- Idle portrait PNG -->
        <img src="zelda.PNG" alt="Zelda Avatar" id="avatarImg" />
        <!-- Tone-based SadTalker clip (src set in JS) -->
        <video
          id="avatarVideo"
          muted
          playsinline
          loop
        ></video>
      </div>

      <div id="avatarName">Zelda</div>
      <div id="avatarSubtitle">Your AI friend & co-pilot</div>
    </div>

    <!-- Chat panel -->
    <div id="chatPanel">
      <div id="chat"></div>

      <div id="inputRow">
        <textarea
          id="messageInput"
          placeholder="Type a message for Zelda..."
          onkeydown="handleInputKeydown(event)"
          rows="2"
        ></textarea>
        <button
          id="micBtn"
          title="Start voice input"
          onclick="toggleRecording()"
        >
          üé§
        </button>
        <button id="sendBtn" onclick="sendMessage()">Send</button>
        <button
          id="voiceBtn"
          title="Toggle Zelda's voice"
          onclick="playLastVoice()"
        >
          üîä
        </button>
      </div>

      <div id="status"></div>
    </div>
	</div> <!-- end #layout -->
  </div> <!-- end #page -->

	<script>
  let BASE_URL;
  if (window.location.protocol === "file:") {
    BASE_URL = "http://127.0.0.1:8000";
  } else {
    BASE_URL = window.location.origin;
  }
  const API_URL = BASE_URL + "/chat";
  const VIDEO_BASE_URL = BASE_URL + "/video/";

  // Map backend tone ‚Üí SadTalker clip
  const toneToVideo = {
    bummed:      "zelda_bummed.mp4",
    caution:     "zelda_caution.mp4",
    encouraging: "zelda_encouraging.mp4",
    excited:     "zelda_excited.mp4",
    happy:       "zelda_happy.mp4",
    intrigued:   "zelda_intrigued.mp4",
    neutral:     "zelda_neutral.mp4",
    playful:     "zelda_playful.mp4",
    reassuring:  "zelda_reassuring.mp4",
    sympathetic: "zelda_sympathetic.mp4",
  };

  // Conversation history sent to backend so it has context.
  let history = [];

  // Last audio URL for replay button
  let lastAudioUrl = null;
  // Single shared Audio object so we can stop/start cleanly
  let currentAudio = null;

  const chatDiv = document.getElementById("chat");
  const messageInput = document.getElementById("messageInput");
  const statusDiv = document.getElementById("status");
  const voiceBtn = document.getElementById("voiceBtn");
  const micBtn = document.getElementById("micBtn");
  const avatarWrapper = document.getElementById("avatarWrapper");
  const avatarVideo = document.getElementById("avatarVideo");

  const MAX_INPUT_HEIGHT = 200; // px

  let isRecording = false;
  let mediaRecorder = null;
  let recordedChunks = [];

  function setSpeakingState(isSpeaking) {
    if (!avatarWrapper) return;
    if (isSpeaking) {
      avatarWrapper.classList.add("speaking");
    } else {
      avatarWrapper.classList.remove("speaking");
    }
  }

  function setAvatarTone(tone) {
    if (!avatarWrapper) return;
    const tones = [
      "tone-sympathetic",
      "tone-encouraging",
      "tone-celebratory",
      "tone-caution",
      "tone-warm_playful",
      "tone-neutral",
    ];
    avatarWrapper.classList.remove(...tones);

    let cls;
    switch (tone) {
      case "sympathetic":
        cls = "tone-sympathetic";
        break;
      case "encouraging":
        cls = "tone-encouraging";
        break;
      case "celebratory":
        cls = "tone-celebratory";
        break;
      case "caution":
        cls = "tone-caution";
        break;
      case "warm_playful":
        cls = "tone-warm_playful";
        break;
      default:
        cls = "tone-neutral";
    }
    avatarWrapper.classList.add(cls);
  }

  function updateAvatarVideoForTone(tone) {
    if (!avatarVideo) return;
    const clip = toneToVideo[tone] || toneToVideo["neutral"];
    const src = VIDEO_BASE_URL + clip;

    // Avoid redundant reloads
    if (avatarVideo.getAttribute("data-src") !== src) {
      avatarVideo.src = src;
      avatarVideo.setAttribute("data-src", src);
    }
  }

  function startAvatarVideo() {
    if (!avatarWrapper || !avatarVideo) return;

    const beginPlayback = () => {
      avatarWrapper.classList.add("playing"); // hide PNG / show video
      try {
        avatarVideo.currentTime = 0;
        avatarVideo.play().catch(err => {
          console.warn("Avatar video play failed:", err);
        });
      } catch (e) {
        console.warn("Error starting avatar video:", e);
      }
    };

    // If the video already has data, start immediately
    if (avatarVideo.readyState >= 2) { // HAVE_CURRENT_DATA
      beginPlayback();
    } else {
      // Wait until the video has enough data to play
      const onCanPlay = () => {
        avatarVideo.removeEventListener("canplay", onCanPlay);
        beginPlayback();
      };
      avatarVideo.addEventListener("canplay", onCanPlay);
    }
  }

  function stopAvatarVideo() {
    if (!avatarWrapper || !avatarVideo) return;
    try {
      avatarVideo.pause();
      avatarVideo.currentTime = 0;
    } catch (e) {
      console.warn("Error stopping avatar video:", e);
    }
    avatarWrapper.classList.remove("playing");
  }

  function setVoiceButtonState(isPlaying) {
    if (!voiceBtn) return;
    // üîä when idle, ‚ùå when "voice active"
    voiceBtn.textContent = isPlaying ? "‚ùå" : "üîä";
    voiceBtn.title = isPlaying
      ? "Stop Zelda's voice"
      : "Play Zelda's voice";
  }

  // Initial state: not playing
  function setMicButtonState(recording) {
    if (!micBtn) return;
    isRecording = recording;
    if (recording) {
      micBtn.textContent = "‚èπ"; // stop icon
      micBtn.title = "Stop recording";

      // Show equalizer + "Listening..." text
      statusDiv.innerHTML = `
        <span id="recordingIndicator">
          <span class="record-bar"></span>
          <span class="record-bar"></span>
          <span class="record-bar"></span>
        </span>
        <span id="recordingLabel">Listening... speak to Zelda.</span>
      `;
    } else {
      micBtn.textContent = "üé§";
      micBtn.title = "Start voice input";
      if (statusDiv.innerHTML.includes("recordingIndicator")) {
        statusDiv.textContent = "";
      }
    }
  }

  // Initial states
  setVoiceButtonState(false);
  setMicButtonState(false);
  setAvatarTone("neutral");

  function autoResizeInput() {
    if (!messageInput) return;
    messageInput.style.height = "auto";
    const newHeight = Math.min(messageInput.scrollHeight, MAX_INPUT_HEIGHT);
    messageInput.style.height = newHeight + "px";
    messageInput.style.overflowY =
      messageInput.scrollHeight > MAX_INPUT_HEIGHT ? "auto" : "hidden";
  }

  if (messageInput) {
    messageInput.addEventListener("input", autoResizeInput);
    autoResizeInput();
  }

  // Handle Enter vs Shift+Enter in the textarea
  function handleInputKeydown(event) {
    if (event.key === "Enter" && !event.shiftKey) {
      event.preventDefault(); // prevent newline
      sendMessage();
    }
    // Shift+Enter -> newline
  }
  window.handleInputKeydown = handleInputKeydown; // ensure it's available from inline handler

  function appendMessage(role, text) {
    const msg = document.createElement("div");
    msg.classList.add("message");
    msg.classList.add(role === "user" ? "user" : "assistant");
    msg.textContent = (role === "user" ? "You: " : "Zelda: ") + text;
    chatDiv.appendChild(msg);
    chatDiv.scrollTop = chatDiv.scrollHeight;
  }

  async function toggleRecording() {
    if (isRecording) {
      // Stop recording
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
      // setMicButtonState(false) will be called in onstop after transcribe
    } else {
      // Start recording
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recordedChunks = [];
        let options = {};
        if (MediaRecorder.isTypeSupported("audio/webm")) {
          options.mimeType = "audio/webm";
        } else if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) {
          options.mimeType = "audio/webm;codecs=opus";
        }

        console.log("MediaRecorder options:", options);

        mediaRecorder = new MediaRecorder(stream, options);

        mediaRecorder.ondataavailable = (event) => {
          if (event.data && event.data.size > 0) {
            recordedChunks.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          try {
            const blob = new Blob(recordedChunks, { type: "audio/webm" });
            await uploadAndTranscribe(blob);
          } catch (e) {
            console.error("Error handling recorded audio:", e);
          } finally {
            setMicButtonState(false);
            // Stop all tracks so mic is released
            stream.getTracks().forEach((t) => t.stop());
          }
        };

        mediaRecorder.start();
        setMicButtonState(true);
      } catch (err) {
        console.error("Error accessing microphone:", err);
        setMicButtonState(false);
      }
    }
  }
  window.toggleRecording = toggleRecording; // for inline onclick

  async function uploadAndTranscribe(blob) {
    try {
      console.log("Recorded blob size (bytes):", blob.size);
      statusDiv.textContent = "Transcribing your speech...";
      const formData = new FormData();
      formData.append("file", blob, "speech.webm");

      const response = await fetch(BASE_URL + "/transcribe", {
        method: "POST",
        body: formData,
      });

      if (!response.ok) {
        throw new Error("Transcription request failed");
      }

      const data = await response.json();
      console.log("Transcribe response:", data);
      const text = (data.text || "").trim();

      if (text) {
        messageInput.value = text;
        autoResizeInput();
        messageInput.focus();
      } else {
        console.log("No transcription text received.");
      }
    } catch (err) {
      console.error("Error during transcription:", err);
    } finally {
      statusDiv.textContent = "";
    }
  }

  async function sendMessage() {
    const text = messageInput.value.trim();
    if (!text) return;

    appendMessage("user", text);
    history.push({ role: "user", content: text });
    messageInput.value = "";
    autoResizeInput();
    statusDiv.textContent = "Zelda is thinking...";

    try {
      const response = await fetch(API_URL, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          message: text,
          history: history,
        }),
      });

      if (!response.ok) {
        throw new Error("Network response was not ok");
      }

      const data = await response.json();
      const reply = data.reply || "(No reply text)";
      const audioUrl = data.audio_url || null;
      const tone = data.tone || "neutral";

      appendMessage("assistant", reply);
      history.push({ role: "assistant", content: reply });

      // Update glow + choose correct SadTalker clip
      setAvatarTone(tone);
      updateAvatarVideoForTone(tone);

      // Store latest audio URL and AUTO-PLAY the new reply.
      if (audioUrl) {
        lastAudioUrl = BASE_URL + audioUrl;

        // Stop existing audio if it's playing
        if (currentAudio && !currentAudio.paused) {
          currentAudio.pause();
          currentAudio.currentTime = 0;
          currentAudio = null;
        }

        // Auto-play the new clip
        try {
          currentAudio = new Audio(lastAudioUrl);
          setVoiceButtonState(true);
          setSpeakingState(true);
          startAvatarVideo();

          currentAudio.onended = () => {
            currentAudio = null;
            setVoiceButtonState(false);
            setSpeakingState(false);
            stopAvatarVideo();
          };
          currentAudio.play().catch(err => {
            console.error("Audio playback failed:", err);
            setVoiceButtonState(false);
            setSpeakingState(false);
            stopAvatarVideo();
          });
        } catch (e) {
          console.error("Error creating audio object:", e);
          setVoiceButtonState(false);
          setSpeakingState(false);
          stopAvatarVideo();
        }
      } else {
        lastAudioUrl = null;
        setVoiceButtonState(false);
        setSpeakingState(false);
        stopAvatarVideo();
      }
    } catch (err) {
      console.error(err);
      appendMessage("assistant", "Oops, something went wrong talking to Zelda.");
    } finally {
      statusDiv.textContent = "";
    }
  }
  window.sendMessage = sendMessage; // for inline onclick

  function playLastVoice() {
    if (!lastAudioUrl) {
      console.log("No voice clip available yet.");
      return;
    }
    try {
      // If something is already playing, stop it and reset (toggle off)
      if (currentAudio && !currentAudio.paused) {
        currentAudio.pause();
        currentAudio.currentTime = 0;
        currentAudio = null;
        setVoiceButtonState(false);
        setSpeakingState(false);
        stopAvatarVideo();
        return;
      }

      // Otherwise, start (or restart) playing the last clip
      currentAudio = new Audio(lastAudioUrl);
      setVoiceButtonState(true);
      setSpeakingState(true);
      startAvatarVideo();

      currentAudio.onended = () => {
        currentAudio = null;
        setVoiceButtonState(false);
        setSpeakingState(false);
        stopAvatarVideo();
      };
      currentAudio.play().catch(err => {
        console.error("Audio playback failed:", err);
        setVoiceButtonState(false);
        stopAvatarVideo();
      });
    } catch (e) {
      console.error("Error controlling audio playback:", e);
      setVoiceButtonState(false);
      stopAvatarVideo();
    }
  }
  window.playLastVoice = playLastVoice; // for inline onclick
</script>
  
</body>
</html>
