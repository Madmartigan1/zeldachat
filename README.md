# ZeldaChat ğŸ§ 
<p align="left">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg" />
  <img src="https://img.shields.io/badge/FastAPI-0.110+-009688.svg" />
  <img src="https://img.shields.io/badge/OpenAI-API-412991.svg" />
  <img src="https://img.shields.io/badge/Frontend-HTML%2FJS-orange.svg" />
  <img src="https://img.shields.io/badge/Status-Experimental-yellow.svg" />
  <img src="https://img.shields.io/badge/License-MIT-green.svg" />
</p>
<p align="center">
  <img src="frontend/calm.png" alt="Zelda avatar" width="150"
       style="border-radius: 50%; margin-right: 20px;" />
  <img src="https://img.shields.io/badge/AI%20Avatar-Real--Time%20Voice%20&%20Video-blue?style=for-the-badge" />
</p>

A local, browser-based chat UI wired to a small FastAPI backend that talks to OpenAI.

It gives you:

- A friendly â€œZeldaâ€ persona using `gpt-4.1-mini` for chat.
- Natural-sounding TTS using `gpt-4o-mini-tts` (voice: `nova`) with prosody shaping so it feels more alive.
- Whisper-based speech-to-text so you can talk to Zelda via microphone instead of just typing.
- A simple avatar front-end (PNG + SadTalker MP4 clips) that reacts in sync with the audio (as best as pre-rendered video allows).

---

## ğŸŒ Project Structure

The repo is intentionally minimal:

```
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ voice.py
â”‚ â”œâ”€â”€ prosody.py
â”‚ â”œâ”€â”€ transcribe.py
â”‚ â”œâ”€â”€ zelda_key.env # your local API key (ignored)
â”‚ â”œâ”€â”€ audio/ # generated audio (ignored)
â”‚ â””â”€â”€ video/ # pre-generated reaction videos
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ index.html
â”‚ â””â”€â”€ zelda.PNG
```

- `main.py` â€“ FastAPI app exposing:
  - `POST /chat` â€“ chat endpoint returning text + `audio_url` + `tone`
  - `POST /transcribe` â€“ transcription endpoint for microphone audio
  - Static `/audio` mount for generated MP3 TTS files
- `voice.py` â€“ TTS helper using OpenAI `gpt-4o-mini-tts` with the `nova` voice and prosody shaping via `prosody.py`.
- `prosody.py` â€“ detects emotional tone of replies and reshapes text for more natural speech delivery, plus exposes `detect_tone()` used by the backend.
- `transcribe.py` â€“ audio transcription via Whisper (`whisper-1`).
- `index.html` â€“ the front-end chat UI with:
  - Typing box + history
  - Mic button (records audio, calls `/transcribe`)
  - â€œPlay Zeldaâ€™s voiceâ€ toggle
  - Zelda avatar (PNG + pre-generated SadTalker MP4 clips)
- `audio/` â€“ auto-created folder for generated MP3 files (served at `/audio/...`).
- `video/` â€“ (optional) SadTalker MP4 clips used by the avatar (e.g. `zelda_happy.mp4`, `zelda_neutral.mp4`, etc.).
- `zelda_key.env` â€“ **not committed**: a single-line file containing your OpenAI API key, read by both `main.py` and `voice.py`.

---

## âœ¨ Features

- ğŸ—£ï¸ **Conversational AI** using `gpt-4.1-mini`
- ğŸ”Š **Natural Text-to-Speech** via `gpt-4o-mini-tts`
- ğŸ¤ **Speech-to-Text** using Whisper
- ğŸ­ **Emotion-based avatar reactions**
- ğŸŒ Pure **local HTML/JS frontend**
- âš¡ Lightweight **FastAPI** backend (`localhost:8000`)

---

## ğŸ”§ Requirements

- Python **3.11+** (3.10 will likely work, but 3.11 is recommended).
- An OpenAI API key with access to:
  - `gpt-4.1-mini` (chat)
  - `gpt-4o-mini-tts` (TTS)
  - `whisper-1` (STT)
- A modern browser (Chrome, Brave, etc.) with microphone access.

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Add your API key

Create a file in /backend named: zelda_key.env and copy/paste your OpenAI key inside


### 3. Load the backend

```
cd backend
uvicorn main:app --reload
```

### 4. Start the frontend

Open frontend/index.html with your browser (Chrome recommended)

---

## ğŸ¤ Contributing 
Pull requests welcome. This is an evolving personal project; improvements and ideas are appreciated. 

--- 

## â­ Acknowledgements 

Built with: 
- Python / FastAPI 
- OpenAI APIs 
- HTML / JavaScript 
- Videos generated with SadTalker: https://github.com/OpenTalker/SadTalker
 
 






